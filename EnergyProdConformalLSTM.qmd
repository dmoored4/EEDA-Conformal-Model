---
title: Optimizing Energy Market Trading with Conformal Predictions and Conditional Value at Risk

format:
    html:
        toc: true
        toc-location: left-body

author:
  - id: dmoored4
    name: Daniel Moore
    affiliations:
      - name: Rutgers University
        department: Industrial and Systems Engineering

  - id: lailaa-salehh
    name: Laila Saleh
    affiliations:
      - name: Rutgers University
        department: Industrial and Systems Engineering

abstract: In this case study, we use data from the Institute of Electrical and Electronic Engineers (IEEE) Hybrid Energy Competition to create a Long Short-Term Memory (LSTM) model to predict the market prices and the combined energy for the Hornsea-1 Wind Farm and a nearby solar farm in eastern England. We then examine the revenue outcomes of different energy trading strategies that use the predictions from the LSTM. This study provides a simple, real-world example of the benefits of proper application of decision-making under uncertainty principles in the energy market. While the LSTM model provides point predictions, we use additional data to obtain probabilistic forecasts which are used to optimize the Conditional Value at Risk (CVaR). The revenue outcomes are greatly improved with CVaR as the trade decisions gain critical context of the uncertainty of the model predictions for both energy production and market prices. This study demonstrates an end-to-end workflow of how data can be ingested, processed into a model, and exploited to reduce financial risk for a renewable energy generation operator. In the long term, reducing this risk is crucial to enticing more renewable energy generation participants which will drive down costs and emissions.
keywords: [Energy Forecasting, Renewable Energy, Energy Analytics, Energy Markets, Conditional Value at Risk, Conformal Prediction, Long Short-Term Memory, LSTM, Julia, Flux, Risk Management]

date: 2024-05-08

bibliography: bibliography.bib
    
execute: 
  echo: FALSE

engine: julia
---

```{julia}
#| label: loading-packages
#| output: false
using Dates
using CSV, DataFrames, StatsPlots, StatsBase
using Flux

gr(
    fontfamily=:Times,
    fmt=:svg
)
```

# Introduction

The IEEE Hybrid Energy Forecasting and Trading Competition @ieeehybridcomp challenges participants to make day-ahead, half-hourly probabilistic forecasts of solar and wind energy production for a solar farm and Hornsea-1 Wind Farm in the east of England with a combined 3.6 GW capacity and then maximize revenue through commitment in the day-ahead market. Any difference between the committed energy and actual energy is traded at the single settlement price (SSP). The implied task is to also forecast the market prices so that the operator can reduce their risk exposure from both the energy production and market prices.

## Motivation

This project serves as a fitting capstone for this course as it applies many topics covered ranging from unit commitment and energy market trading to advanced predictive and prescriptive analytics for complex and uncertain events. It is an interesting and practical opportunity to wrestle with the available resources to make the best decisions for the operator. Lastly, we find it a compelling problem because reducing the risk for renewable energy generation operators will encourage more participation and be of a net benefit to investors, consumers, and the environment.

## Objectives

Our primary objective is to maximize the operator's revenue by making bids on the day-ahead market which minimizes risk based on the forecasted energy production and market prices. We achieve this by training a Long Short-Term Memory (LSTM) model to make point predictions of these values for the next day. We then employ methods to quantify the uncertainty of these predictions. First, we use Conformal Prediction (CP) to calculate prediction intervals which give some assurance that our bid will be within some range above or below the predicted value and evaluate the revenues from this. Then, we use Conditional Value at Risk (CVaR) by generating scenarios that simulate the errors in our predictions and set a bid that maximizes revenue while minimizing the risk of a worst-case scenario.

## Literature Review

Conformal prediction, or conformal inference is a user-friendly method to quantify uncertainty intervals for models. These intervals are distribution-free in the sense that they have explicit, non-asymptotic guarantees without distribution or model assumptions @DBLP:journals/corr/abs-2107-07511. This is useful in the implementation of our project because it is used to determine the uncertainty without assuming an underlying distribution, potentially skewing the confidence intervals. It uses a calibration dataset to make accurate inferences about the uncertainty of the model that was trained on a training data set. Another trading approach is to use scenarios to simulate future eventualities and evaluate the outcome of different decisions in those scenarios. This approach uses an optimization model to optimize a bidding curve that allows the operator to stabilize revenue and avoid risks @Xu2020-ib. This approach aims to avoid risky bidding policies for the operator to protect against worst-case scenarios by making more conservative bids to minimize risk. Both these approaches are areas of research that we implement and compare the results.

# Data Analysis

We have obtained datasets from two sources: the competition itself which provides the energy production data through the Rebase API @RebaseApi and the VisualCrossing API @VisualCrossing which provides the weather data. The energy data details the solar production, wind production, DAP, and SSP in half-hourly increments. The weather data is treated as historic for the period preceding a given forecast and as a weather forecast for the forecast horizon. If deployed, the model would need to operate only using forecasted weather data. This approach is acceptable for this study as 48-hour-ahead weather forecasts are typically very accurate and we are only incorporating basic weather features.

## Data Insights

@tbl-energy-data-summary and @tbl-weather-data-summary provide summary statistics for the energy and weather data used throughout this report. We have the amount of power produced from solar, wind, and combined total power as well as DAP and SSP. The DAP is the Intermittent Market Reference Price published by the Low Carbon Contracts Company. It is the weighted average of the prices from Great Britain's two-day-ahead auctions, operated by NordPool and EPEX Spot. The SSP is calculated and distributed by Elexon and is the price paid for energy imbalances in the market. As our task is to make bids on the total energy rather than the solar or wind specifically, we combine these two as Total Energy. This quantity is less volatile than the individual sources as adding two random variables or convoluting them will reduce the variance. This effect is observed as we see the median total energy is greater than the sum of the median solar and wind energy and the mean value is closer to the median value. For the market prices we see similar mean and median values in the DAP and SSP but the domain of the SSP is much larger. Also, it is notable that both have negative values indicating there are times of an energy surplus being penalized by the market.

```{julia}
#| label: loading-data
#| output: false
energy_cols = [:Solar, :Wind, :TotalEnergy, :DAP, :SSP]
weather_cols = [:temp, :windspeed, :winddir, :cloudcover, :visibility]

function getdata()
    data = CSV.read("src/data/data_rebase.csv", DataFrame)

    select!(data,
        :timestamp_utc => :DateTime,
        :solar_act => :Solar,
        :wind_act => :Wind,
        :dayahead_price => :DAP,
        :imbalance_price => :SSP)

    data.TotalEnergy = data.Solar + data.Wind


    data.temptime = floor.(data.DateTime, Hour(1))


    unique!(data)

    weather = CSV.read("src/data/hornsea 2024-02-29 to 2024-04-06.csv", DataFrame)
    weather = [weather; CSV.read("src/data/hornsea 2024-04-06 to 2024-04-30.csv", DataFrame)]

    select!(weather,
        :datetime => :DateTime,
        :temp,
        :windspeed,
        :winddir,
        :cloudcover,
        :visibility
    )

    unique!(weather)

    data = leftjoin(data, weather, on=:temptime => :DateTime)

    filter!(row -> !any(ismissing, row), data)

    select!(data, Not(:temptime))
    select!(data, [:DateTime; weather_cols; energy_cols])

    data[!, Not(:DateTime)] = Float32.(data[!, Not(:DateTime)])

    sort!(data, :DateTime)

    return data
end

data = getdata()
```

::: {#tbl-energy-data-summary}
```{julia}
#| label: rebase-data-summary
rebase_summary = describe(data, :mean, :min, :median, :max, cols=energy_cols)
rebase_summary.variable = ["Solar MW/hr", "Wind MW/hr", "Total Energy MW/hr", "DAP GBP/MWh", "SSP GBP/MWh"]
rebase_summary
```
Rebase Energy Data Summary
:::

Looking at the tabular summary of the weather data in @tbl-weather-data-summary, we observe that the mean and medians are roughly in the middle of the feature ranges for all, but cloud cover. With a mean of 71% and a median of 92%, we see that the data is heavily skewed towards being more cloudy.

::: {#tbl-weather-data-summary}
```{julia}
#| label: weather-data-summary
weather_summary = describe(data, :mean, :min, :median, :max, cols=weather_cols)
weather_summary.variable = ["Temperature (°C)", "Wind Speed (kph)", "Wind Direction (°)", "Cloud Cover (%)", "Visibility (km)"]
weather_summary
```
Weather Data Summary
:::

## Data Visualizations

```{julia}
#| label: plotting-conveniences
#| output: false
function every4hrs_date_noon(dt)
    if hour(dt) % 4 == 0 & minute(dt) == 0
        if hour(dt) == 12
            Dates.format(dt, "u-d HH:MM")
        else
            Dates.format(dt, "HH:MM")
        end
    end
end


monthly_ticks = (
    DateTime(Date(data.DateTime[findfirst(d -> dayofweek(d) == Sun, data.DateTime)]), Time(12)):Week(1):last(data.DateTime), Dates.format.(
        DateTime(Date(data.DateTime[findfirst(d -> dayofweek(d) == Sun, data.DateTime)]), Time(12)):Week(1):last(data.DateTime),
        "u-d"
    )
)

daily_xticks = (Time(0):Hour(3):Time(23), Dates.format.(Time(0):Hour(3):Time(23), "HH:MM"))

cmap = Dict(
    "DAP" => :darkgreen,
    "SSP" => :orange,
    "temp" => :darkred,
    "Solar" => :darkgoldenrod1,
    "Wind" => :darkblue,
    "CloudCover" => :darkgrey,
    "TotalEnergy" => :hotpink,
)

clouds = cgrad([:gold, :darkgrey])
winds = cgrad([:white, :blue])
temp = cgrad(:turbo)
visibiilty = cgrad([:white, :darkblue])
energy_prod = cgrad([:white, :hotpink])
```

We first examine the histograms of our weather and energy features. The weather data is consistent with what could be ascertained from the summary statistics previously. @fig-weather-data-summary-histogram shows the distribution of these features.

:::{#fig-weather-data-summary-histogram}
```{julia}
#| label: weather-data-summary-histogram

@df data plot(
    legend=false,
    histogram(:temp, color=:darkred, xlabel="Temperature (°C)"),
    histogram(:windspeed, color=:lightblue, xlabel="Wind Speed (kph)"),
    histogram(:cloudcover, color=:darkgrey, xlabel="Cloud Cover (%)"),
    histogram(:visibility, color=:darkblue, xlabel="Visibility (km)")
)
```
Weather Data Histograms
:::

The histograms of the energy data in @fig-energy-data-summary-histogram provide a new context for our analysis. We observe how the Total Energy resembles a Normal distribution compared to the Exponential decay of the Solar Energy and the Beta distribution of the Wind Energy. The market prices also resemble a normal distribution with two notable exceptions. They both have fat tails which indicates there are times when very low prices are observed with relative frequency. This is a primary source of risk for trading. The second difference is that the SSP exhibits a bimodal distribution. The fat left tail of the SSP is associated with energy surplus, the right peak is associated with energy deficit, and the central peak is the price when the system is relatively balanced. This sets up several distinct states of the system which could greatly alter the best trading bid regardless of the actual energy production. For instance, if the system is in a deficit, a high-risk operator could commit no energy and trade everything produced at a price that is possibly much higher than the day ahead price. In reality, this likely requires more knowledge of the future and control of the system than is available to any operator and any arbitrage situation would quickly be eliminated by the market.

:::{#fig-energy-data-summary-histogram}
```{julia}
#| label: energy-data-summary-histogram

@df data plot(
    legend=false,
    histogram(:Solar, color=cmap["Solar"], xlabel="Solar"),
    histogram(:Wind, color=cmap["Wind"], xlabel="Wind"),
    histogram(:TotalEnergy, color=cmap["TotalEnergy"], xlabel="Total Energy"),
    histogram(:DAP, color=cmap["DAP"], xlabel="DAP"),
    histogram(:SSP, color=cmap["SSP"], xlabel="SSP"),
)
```
Energy Data Histograms
:::

Next, we study the day-ahead and then the single settlement prices as time histories and their correlations to weather and daily seasonality in @fig-monthly-dap-energy-price-plots and @fig-monthly-ssp-energy-price-plots. In each group of plots, the top plot shows the entire history of the data while the second provides a closer look at a single week. The bottom plots show the prices vs. temperature and total energy production with the right side showing the daily seasonality. The relative variability of the SSP compared to the DAP is highlighted by the scales being the same in the first and second plots.

For the DAP plots in @fig-monthly-dap-energy-price-plots, we see a clear pattern with a few random dips in the price but eventually returning to the seasonal mean. The week plot provides a clearer look at the typical pattern. The daily seasonal plot shows the duck curve associated with high prices in the morning and evening which is driven by both energy production and cyclical demand. The shape of the curves is there is a concentrated group at the upper end of the prices, but there are many times when price curves are much lower.
In the temperature plot, we see that the price tends to show the same general fluctuations regardless of the temperature. There are two days around April 9th which seem to have low costs associated with the warmest days. This relative price indifference to temperature is unexpected but may be explained by the type of weather typical for this region and the current lack of air conditioning systems. The bottom plot shows how the price changes with total energy production from solar and wind. We cannot pick an obvious pattern looking at the monthly plot, but we can see that prices are generally higher at times of day when production is higher. There are two drivers which are somewhat counteracting each other. The first is that demand is typically going to be higher because people are awake and using electricity. At the same time, production is higher because the sun is up and powering solar panels. The dynamics in the system are complex as price, demand, weather, and production are inextricably linked.

:::{#fig-monthly-dap-energy-price-plots}
```{julia}
#| label: monthly-dap-energy-price-plots
@df data plot(
    size=(800, 600),
    layout = @layout([
        month_plt
        week_plt
        month_temp{0.5w} daily_temp{0.5w} temp_cbar
        month_wind{0.5w} daily_wind{0.5w} wind_cbar
        ]),
    legend=false,
    # monthly plot
    begin
        plot(
            ylabel="DAP (£/MWh)",
            :DateTime, :DAP,
            label="DAP", color=cmap["DAP"],
            ylims=1.1 .* extrema(:SSP),
        )
        hline!([0], lw=0.5, lc=:black, α=0.5, label=false)
    end,

    # 1-week plot
    begin
        plot(
            ylabel="DAP (£/MWh)",
            :DateTime, :DAP,
            label="DAP", color=cmap["DAP"],
            ylims=1.1 .* extrema(:SSP),
            xlims=(DateTime(2024, 3, 10), DateTime(2024, 3, 17))
        )
        hline!([0], lw=0.5, lc=:black, α=0.5, label=false)
    end,

    # temperature plots
    # monthly
    begin
        plot(
            ylabel="DAP (£/MWh)",
            :DateTime, :DAP,
            label="DAP",
            line_z=:temp, color=temp, cbar=false,
        )
        hline!([0], lw=0.5, lc=:black, α=0.5, label=false)
    end,
    # daily
    plot(
        xticks = (Time.(Hour.(0:6:23)), [Dates.format(x, "HH:MM") for x in Time.(Hour.(0:6:23))]),
        Time.(:DateTime), :DAP,
        group=Date.(:DateTime),
        line_z=:temp, color=temp, cbar=false
    ),
    plot(
        xlims=(0,0),
        [-2, -2],
        [-2, -2],
        line_z = [extrema(:temp)...], label=false,
        color=temp, cbartitle="°C", framestyle=:none
    ),

    # wind plots
    # monthly
    begin
        plot(
            ylabel="DAP (£/MWh)",
            :DateTime, :DAP,
            label="DAP",
            line_z=:TotalEnergy, color=energy_prod, cbar=false
        )
        hline!([0], lw=0.5, lc=:black, α=0.5, label=false)
    end,
    # daily
    plot(
     xticks = (Time.(Hour.(0:6:23)), [Dates.format(x, "HH:MM") for x in Time.(Hour.(0:6:23))]),
        Time.(:DateTime), :DAP,
        group=Date.(:DateTime),
        line_z=:TotalEnergy, color=energy_prod, cbar=false
    ),
    # cbar
    plot(
        xlims=(0,0),
        [-2, -2],
        [-2, -2],
        line_z = [extrema(:TotalEnergy)...], label=false,
        color=energy_prod, cbartitle="Energy Production (MWh)", framestyle=:none
    )
)
```
Day Ahead Prices. Top: complete time history. Middle: one-week history. Bottom Left: price history vs. temperature (top) and total energy production (bottom). Bottom right: daily seasonality of price vs. temperature (top) and total energy production (bottom).
:::

We see different characteristics with the SSP plots in @fig-monthly-ssp-energy-price-plots as the signal is hardly distinguishable from a random walk. The domain of the SSP is 
The SSP is a different story as the time series is twice that of the DAP and it traverses from low values to high values in cycles that are not obvious. The only seasonality observed is that around 18:00, the SSP typically constricts to a range between about 25 and 100. The curves themselves look like spaghetti which further indicates that the change in SSP is practically random. As mentioned above, if the SSP became predictable, the market would eliminate the arbitrage opportunity.

:::{#fig-monthly-ssp-energy-price-plots}
```{julia}
#| label: monthly-ssp-energy-price-plots
@df data plot(
    size=(800, 600),
    layout = @layout([
        month_plt
        week_plt
        month_temp{0.5w} daily_temp{0.5w} temp_cbar
        month_wind{0.5w} daily_wind{0.5w} wind_cbar
        ]),
    legend=false,
    # monthly plot
    begin
        plot(
            ylabel="SSP (£/MWh)",
            :DateTime, :SSP,
            label="SSP", color=cmap["SSP"],
            ylims=1.1 .* extrema(:SSP),
        )
        hline!([0], lw=0.5, lc=:black, α=0.5, label=false)
    end,

    # 1-week plot
    begin
        plot(
            ylabel="SSP (£/MWh)",
            :DateTime, :SSP,
            label="SSP", color=cmap["SSP"],
            ylims=1.1 .* extrema(:SSP),
            xlims=(DateTime(2024, 3, 10), DateTime(2024, 3, 17))
        )
        hline!([0], lw=0.5, lc=:black, α=0.5, label=false)
    end,

    # temperature plots
    # monthly
    begin
        plot(
            ylabel="SSP (£/MWh)",
            :DateTime, :SSP,
            label="SSP",
            line_z=:temp, color=temp, cbar=false,
        )
        hline!([0], lw=0.5, lc=:black, α=0.5, label=false)
    end,
    # daily
    plot(
        xticks = (Time.(Hour.(0:6:23)), [Dates.format(x, "HH:MM") for x in Time.(Hour.(0:6:23))]),
        Time.(:DateTime), :SSP,
        group=Date.(:DateTime),
        line_z=:temp, color=temp, cbar=false
    ),
    plot(
        xlims=(0,0),
        [-2, -2],
        [-2, -2],
        line_z = [extrema(:temp)...], label=false,
        color=temp, cbartitle="°C", framestyle=:none
    ),

    # wind plots
    # monthly
    begin
        plot(
            ylabel="SSP (£/MWh)",
            :DateTime, :SSP,
            label="SSP",
            line_z=:TotalEnergy, color=energy_prod, cbar=false
        )
        hline!([0], lw=0.5, lc=:black, α=0.5, label=false)
    end,
    # daily
    plot(
     xticks = (Time.(Hour.(0:6:23)), [Dates.format(x, "HH:MM") for x in Time.(Hour.(0:6:23))]),
        Time.(:DateTime), :SSP,
        group=Date.(:DateTime),
        line_z=:TotalEnergy, color=energy_prod, cbar=false
    ),
    # cbar
    plot(
        xlims=(0,0),
        [-2, -2],
        [-2, -2],
        line_z = [extrema(:TotalEnergy)...], label=false,
        color=energy_prod, cbartitle="Energy Production MWh", framestyle=:none
    )
)
```
Single Settlement Prices. Top: complete time history. Middle: one-week history. Bottom Left: price history vs. temperature (top) and total energy production (bottom). Bottom right: daily seasonality of price vs. temperature (top) and total energy production (bottom).
:::

The next data visualization in @fig-violin-plots depicts a statistical summary of the energy production and market prices for each day in the period as well as grouped by day of the week and hour of the day. The violin plots indicate the density of observations near that level for the given group. The boxplots quantify the spread by showing the mean, quartiles, and outliers. These plots capture the trend over the entire time and the daily seasonality better than a single time series plot. Where before the SSP looked like a random walk, we can observe some correlation to the DAP. Still, we note that the variance of the SSP is much wider. The duck curve for the DAP is more pronounced and we see there is a fairly tight first quartile, but with outliers far beyond this range. Lastly, we note that the energy production is somewhat random over a longer period, but fairly consistent on a daily cycle.

:::{#fig-violin-plots}
```{julia}
#| label: violin-plots

@df data plot(
    size=(800, 500),
    layout=@layout([
        m{0.5w} w{0.25w} d{0.25w}
        m{0.5w} w{0.25w} d{0.25w}
        m{0.5w} w{0.25w} d{0.25w}
    ]),
    ms=2,

    begin
		@df data violin(
            ylabel="DAP",
			Date.(:DateTime), :DAP, label=false,
			color=cmap["DAP"], α=0.5,
            xticks=false,
		)

		@df data boxplot!(
			Date.(:DateTime), :DAP, label=false,
			color=:black, α=0.2
		)
    end,
    begin
		@df data violin(
			dayofweek.(:DateTime), :DAP, label=false,
			color=cmap["DAP"], α=0.5,
            xticks=false, yticks=false,
		)

		@df data boxplot!(
			dayofweek.(:DateTime), :DAP, label=false,
			color=:black, α=0.2
		)
    end,
        begin
		@df data violin(
			hour.(:DateTime), :DAP, label=false,
			color=cmap["DAP"], α=0.5,
            xticks=false, yticks=false,
		)

		@df data boxplot!(
			hour.(:DateTime), :DAP, label=false,
			color=:black, α=0.2
		)
    end,

    begin
		@df data violin(
            ylabel="SSP",
			Date.(:DateTime), :SSP, label=false,
			color=cmap["SSP"], α=0.5,
            xticks=false
		)

		@df data boxplot!(
			Date.(:DateTime), :SSP, label=false,
			color=:black, α=0.2
		)
    end,
    begin
		@df data violin(
			dayofweek.(:DateTime), :SSP, label=false,
			color=cmap["SSP"], α=0.5,
            xticks=false, yticks=false,
		)

		@df data boxplot!(
			dayofweek.(:DateTime), :SSP, label=false,
			color=:black, α=0.2
		)
    end,
        begin
		@df data violin(
			hour.(:DateTime), :SSP, label=false,
			color=cmap["SSP"], α=0.5,
            xticks=false, yticks=false,
		)

		@df data boxplot!(
			hour.(:DateTime), :SSP, label=false,
			color=:black, α=0.2
		)
    end,

    begin
		@df data violin(
            xlabel="Date",
            ylabel="Total Energy",
			Date.(:DateTime), :TotalEnergy, label=false,
			color=cmap["TotalEnergy"], α=0.5
		)

		@df data boxplot!(
			Date.(:DateTime), :TotalEnergy, label=false,
			color=:black, α=0.2
		)
    end,
    begin
		@df data violin(
            xlabel="Day of Week",
            xticks= (1:7, ["M" "T" "W" "Th" "F" "Sa" "Su"]),
			dayofweek.(:DateTime), :TotalEnergy, label=false,
			color=cmap["TotalEnergy"], α=0.5,
            yticks=false,
		)

		@df data boxplot!(
			dayofweek.(:DateTime), :TotalEnergy, label=false,
			color=:black, α=0.2,
            yticks=false,
		)
    end,
        begin
		@df data violin(
            xlabel="Hour",
            xticks=(0:6:23, [Dates.format(Time(h, 0), "HH:MM") for h in 0:6:23]),
			hour.(:DateTime), :TotalEnergy, label=false,
			color=cmap["TotalEnergy"], α=0.5,
            yticks=false,
		)

		@df data boxplot!(
			hour.(:DateTime), :TotalEnergy, label=false,
			color=:black, α=0.2,
            yticks=false,
		)
    end
)
```
Statistical summary of the energy production and market prices for each day in the period as well as grouped by day of the week and hour of the day.
:::

The pairplot in @fig-correlation-plots the direct correlation or lack thereof among the key variables. Cloud cover is not a strong indicator for two reasons. First, it would have the strongest impact on the system during the daytime only. Second, it is an asymmetric feature skewed towards very cloudy. Windspeed is a strong predictor of total energy as expected and there is a negative trend between total energy production and market prices. This indicates that our system is not an outlier from others in this grid as all correlations are as expected.

:::{#fig-correlation-plots}
```{julia}
#| label: correlation-plots


@df data corrplot(
    [:cloudcover :windspeed :TotalEnergy :DAP :SSP],
    size=(800, 600),
    grid=false,
    ms=2,
    bins=20
)
```
Correlation PairPlot
:::

The group of marginal kernel density estimate (KDE) plots in @fig-marginal-kde offer a final visualization of the correlation among the key features. At the top left we see a slight positive correlation between Total Energy and Wind Speed. At the top right, we observe that the DAP and Total Energy are perpendicular to each other, indicating no correlation. The same observation is true for the Total Energy and SSP in the bottom left. In the bottom right we see two correlated regions. Most significantly, we see that the very negative SSP prices are associated with the lowest DAP prices. Then we see a general correlation for the main region of prices but the two upper peaks of the SSP are independent of the DAP.

:::{#fig-marginal-kde}
```{julia}
#| label: marginal-kde

@df data plot(
    marginalkde(
        :TotalEnergy, :windspeed,
        xlabel="Total Energy (MW/hr)",
        ylabel="Wind Speed (kph)",
    ),
    marginalkde(
        :TotalEnergy, :DAP,
        xlabel="Total Energy (MW/hr)",
        ylabel="DAP (£/MWh)",
    ),
    marginalkde(
        :TotalEnergy, :SSP,
        xlabel="Total Energy (MW/hr)",
        ylabel="SSP (£/MWh)",
    ),
    marginalkde(
        :DAP, :SSP,
        xlabel="DAP (£/MWh)",
        ylabel="SSP (£/MWh)",
    )
)
```
Marginal KDEs. Top Left: Total Energy vs. Wind Speed. Top Right: Total Energy vs. DAP. Bottom Left: Total Energy vs. SSP. Bottom Right: DAP vs. SSP.
:::

## Data Conclusions
The analysis of the time series and correlations among the data support our hypothesis that there are predictable dynamics at play which would allow for accurate predictions. However, the dynamics are not straightforward and highly nonlinear. We consider this system to be an ideal one to model with a neural network as it can approximate any function. While we lose explainability and we are only left with a point forecast, we can use the methods mentioned at the outset to use the predictions in probabilistic trading strategies. The next section will detail the LSTM model we used to make these predictions.

# Long Short-Term Memory Model

We implemented an LSTM recurrent neural network (RNN) multi-target regressor to predict the solar, wind, total energy, DAP, and SSP for the next time step. We selected an LSTM over a generic RNN or Gated Recurrent Unit (GRU) because LSTMs solve the so-called vanishing gradient problem associated with generic RNN but still exhibit longer "memory" of past events compared to GRUs. The complex dynamics among the features can be approximated by the dense output layer. Outputting all targets at once is computationally efficient and provides the model with additional information when updating the parameters. The seasonality of the solar production and DAP were provided directly a sinusoidal waves with periods of 24 hours and 12 hours, respectively. All inputs and outputs were normalized so that the different scales of the multi-target regression targets would not affect the model's learning.

```{julia}
#| label: data-transforms
#| output: false
#| eval: false
transforms = Dict(
    col_name =>
        fit(UnitRangeTransform, data[!, col_name]) for col_name in [weather_cols..., energy_cols...]
)

function transform_data(data;
    dt_col = :DateTime,
    weather_cols = weather_cols,
    energy_cols = energy_cols)
    
    data_xfrm = transform(select(data, [dt_col, weather_cols..., energy_cols...]),
        renamecols=false,
        dt_col => 
            dt -> (1 .- cos.((hour.(dt) + minute.(dt)/60) * 2π/24))/2,
        [col => x -> StatsBase.transform(transforms[col], x) for col in vcat(weather_cols, energy_cols)]
    )

    data_xfrm.twelvehr = [(1 .- cos.((hour.(dt) + minute.(dt)/60) * 2π/12))/2 for dt in data[:, dt_col]]

    select!(data_xfrm, dt_col, :twelvehr, :)

    return data_xfrm
end

function reconstruct_data!(data;
    weather_cols = [], energy_cols = energy_cols)
    data_xfrm = transform(
        select(data, [weather_cols..., energy_cols...]),
        renamecols=false,
        [col => x -> StatsBase.reconstruct!(transforms[col], x) for col in vcat(weather_cols, energy_cols)]
    )

    return data_xfrm
end

function batchsequences(data; batch_size = 2^5)
    M = Matrix(data)' .|> Float32

    # first turn into a vector of n x batches
    # n is number of features
    batches = [M[:, i:i+batch_size-1] for i in 1:size(M, 2)-batch_size+1]
    
    #=
    now we need to offset everything a couple different ways. we need to have the inputs for predicting the energy at time, t be:
    - the time and weather at time t
    - the energy at time t-1

    Then we need the target to be the energy at time t
    =# 
    next_time_weather = [b[1:end-length(energy_cols), :] for b in batches[2:end]]
    
    this_energy = [b[end-length(energy_cols)+1:end, :] for b in batches[1:end-1]]
    
    past = [[w; e] for (w, e) in zip(next_time_weather, this_energy)]

    next_energy = this_energy[2:end]

    batches = [(past=p, next=n) for (p, n) in zip(past, next_energy)]

    return batches
end
```

```{julia}
#| label: data-split
#| output: false
#| eval: false
train_ratio = 0.45
calib_ratio = 0.35

train_idx = 1:floor(Int, train_ratio * nrow(data))
calib_idx = (last(train_idx) + 1):floor(Int, (train_ratio + calib_ratio) * nrow(data))
test_idx = (last(calib_idx) + 1):nrow(data)

Train = batchsequences(transform_data(data[train_idx, :]))
Calib = batchsequences(transform_data(data[calib_idx, :]))
Test = batchsequences(transform_data(data[test_idx, :]))
```

## Training

We used Julia's deep learning library, Flux @Flux.jl-2018, to build and train the LSTM. The workflow is as follows:

1. Define the loss function. We used mean squared error as we wanted to penalize outliers.
2. Build the LSTM. Our LSTM consists of two LSTM layers followed by a dense output layer with a sigmoid activation. The input size, twelve, is the length of the weather and energy columns plus two for the seasonality components. The output length, five, is the length of the energy columns. The hidden dimension size is eight. This results in a model with 1,293 trainable parameters.
3. Set up the optimizer. We used the Adam optimizer with a learning rate of 1e-4.
4. Train the model on the training data. A special note for training LSTMs is that it can be important to reset the LSTM and then call it on the first batch of data before training it on the subsequent batches. This primes the LSTM's hidden state so that gradients are based on the recent data and not some arbitrary state. We trained the model for 128 epochs on 45% of the available data with batch sizes of 32.

```{julia}
#| label: set-loss
#| output: false
#| eval: false
loss(model, x, y) = Flux.mse(model(x), y)
loss(model, data) = loss(model, data.past, data.next)
```

```{julia}
#| label: build-LSTM
#| output: false
#| eval: false
input_dims = 2 + length(weather_cols) + length(energy_cols)
out_dims = length(energy_cols)
hidden_dim = 2^3
model = Chain(
    LSTM_in=LSTM(input_dims, hidden_dim),
    LSTM_hidden1=LSTM(hidden_dim, hidden_dim),
    Dense_out=Dense(hidden_dim, out_dims, σ)
)

train_loss_log = [loss(model, first(Train))]
test_loss_log = [loss(model, first(Test))]

model
```

```{julia}
#| label: setup-optimizer
#| output: false
#| eval: false
η = 1e-4
opt_state = Flux.setup(Adam(η), model)
```

```{julia}
#| label: train-function
#| output: false
#| eval: false
function train!(loss, model, data, opt_state; loss_log=[])
    L, ∇ = Flux.withgradient(loss, model, data)

    if !isfinite(L)
        @warn "Loss value, \"$L\" is invalid."
    else
        Flux.update!(opt_state, model, ∇[1])
    end

    push!(loss_log, L)
end
```

```{julia}
#| label: training-loop
#| output: false
#| eval: false

# Number of epochs
epochs = 2^7

for epoch in 1:epochs

    # intializing a log for the training loss for this epoch
    temp_train_log = []
    # Resetting the model state
    Flux.reset!(model)
    # conditioning on the first training sequence
    model(first(Train).past)
    # training on the first training sequence
    for T in Train[2:end]
        train!(loss, model, T, opt_state, loss_log=temp_train_log)
    end
    
    # logging the mean training loss for this epoch
    push!(train_loss_log, mean(temp_train_log))
    Flux.reset!(model)
    model(first(Test).past)
    push!(test_loss_log, mean(loss(model, T) for T in Test))
end
```

```{julia}
#| label: plot-loss
#| fig-cap: "Training and Testing Loss"
#| fig-alt: "Plot of training and testing loss"
#| eval: false
plot(
    xlabel="Epochs",
    ylabel="Mean Squared Error",
    [train_loss_log test_loss_log], label=["Training Loss" "Testing Loss"],
    markershape=[:o :^], markerstrokewidth=0,
    xscale=:log2, xticks= 2 .^ (0:8)
)
```

```{julia}
#| label: make_predictions
#| output: false
#| eval: false
function predict_daterange(df, first_prediction, last_prediction)
    # 
    first_pred_index = findfirst(
        dt -> dt ≥ first_prediction, df.DateTime)
    last_pred_index = findlast(
        dt -> dt ≤ last_prediction, df.DateTime)
    
    current_idx = first_pred_index - (2 * 24)


    # store predicted dates to join with predictions at the end
    # this allows us to combine it back to the original data
    pred_dates = df[current_idx:last_pred_index, :DateTime]

    # transform the data
    df = transform_data(df)
    # batch the data. We now have a batch size of 1 because
    # we are predicting the entire dataset in sequence
    batched = batchsequences(df, batch_size=1)

    # reset the model internal state
    Flux.reset!(model)
    # iterate over the data up to the first prediction
    for i in 1:current_idx-1
        # run the model just to update the internal state
        model(batched[i].past)
    end

    # store the first prediction
    results = [model(batched[current_idx].past)]
    # iterate over the rest of the data
    # use the time and weather columns for batch[j][time+weather, ] and the last of predictions
    for j in current_idx+1:last_pred_index
        new_result = model([batched[j].past[1:2+length(weather_cols), :]; results[end]])
        push!(results, new_result)
    end

    # concatenate the results into a matrix
    results = hcat(results...)'

    # reconstruct the data
    results = DataFrame(results, energy_cols) |> reconstruct_data!

    # add the DateTime column
    results.DateTime = pred_dates

    filter!(row -> row.DateTime ≥ first_prediction && row.DateTime ≤ last_prediction, results)
    
    return results
end

# predict the entire dataset
function predict_all(data)
    # get the unique days. We need to predict one day at a time starting at 8:30
    days = unique(Date.(data.DateTime))
    results = []
    # 
    for d in days[3:end-1] 
        first_prediction = DateTime(d, Time(8, 30))
        last_prediction = first_prediction + Day(1)
        push!(results, predict_daterange(data, first_prediction, last_prediction))
    end

    # concatenate the results
    results = vcat(results...)

    select!(results, [:DateTime; energy_cols])

    # rename all energy_cols to have "_pred" appended
    for col in energy_cols
        rename!(results, col => Symbol(string(col, "_pred")))
    end

    return results
end

#| output: false
all_predictions = predict_all(data)

# join the predictions with the original data
all_predictions = leftjoin(all_predictions, data, on=:DateTime)

# write the predictions to a file
# CSV.write("src/data/predictions.csv", all_predictions)
```

```{julia}
#| label: load-predictions
#| output: false
# all_predictions = CSV.read("src/data/predictions.csv", DataFrame)
```

```{julia}
#| label: load-group-predictions
#| output: false
data = CSV.read("src/data/data_predictions_revenues.csv", DataFrame)
data = groupby(data, :dataset)
```

## Performance

We simulated the trading environment by making predictions up to 48 hours out from a given time. For instance, we would run the model on data up to 8:00 AM on Monday, the time at which we must submit bids for the period of 8:30 AM Tuesday to 8:00 AM Wednesday. Beginning at 8:30 AM on Monday, the model pulls "forecasted" weather data and its own latest predictions to predict the next outputs. This continues until the prediction period is complete. We observe the performance on the testing data below.

Qualitatively, we observe the LSTM predictions in @fig-predictions are sensible and follow the general characteristics of the target variables. The predicted values are plotted in color over the actual values in grey. The solar and wind predictions capture the general moving average but are not as accurate individually as the total energy predictions. The DAP prediction also generally captures the trend and seasonality of the actual values. The SSP predictions are, as expected, less precise than the other predictions. It is unable to capture the random fluctuations in the values but it stays in the general range of the actual values.

:::{#fig-predictions}
```{julia}
#| label: plot-predictions

@df data[("test", )] plot(
    xlims=(DateTime(2024, 4, 14, 8, 30), DateTime(2024, 4, 20, 8, 00)),
    layout=@layout((5, 1)),
    legend=false,
    size=(800, 600),
    plot(
        ylabel="Solar",
        :DateTime, [:Solar :Solar_pred],
        color=[:grey cmap["Solar"]], lw=[4 2], α=[0.5 1]
    ),
    plot(
        ylabel="Wind",
        :DateTime, [:Wind :Wind_pred],
        color=[:grey cmap["Wind"]], lw=[4 2], α=[0.5 1]
    ),
    plot(
        ylabel="Total Energy",
        :DateTime, [:TotalEnergy :TotalEnergy_pred],
        color=[:grey cmap["TotalEnergy"]], lw=[4 2], α=[0.5 1]
    ),
    plot(
        ylabel="DAP",
        :DateTime, [:DAP :DAP_pred],
        color=[:grey cmap["DAP"]], lw=[4 2], α=[0.5 1]
    ),
    plot(
        ylabel="SSP",
        :DateTime, [:SSP :SSP_pred],
        color=[:grey cmap["SSP"]], lw=[4 2], α=[0.5 1]
    )
)
```
Test Data Predictions
:::

We check the Mean Absolute and Root Mean Squared Error for all three testing sets to ensure the model is not overfitting. The results are shown in @tbl-MAE-error and @tbl-RMSE-error. The error values are fairly consistent across datasets for the two error measures indicating that we have not overfit the model. The errors are typically worse in the test but not to the point of overfitting. More than likely, there are some events present in the test data that are not observed in the training data. The best way to improve this would be to increase the history of the training data.

:::{#tbl-MAE-error}
```{julia}
#| label: test-error

MAE_df = DataFrame(
    feature = energy_cols,
    Train = [mean(abs.(
        data[("train", )][:, col] .-
        data[("train", )][:, string(col, "_pred")]))
        for col in energy_cols
    ],
    Calib = [mean(abs.(
        data[("calib", )][:, col] .-
        data[("calib", )][:, string(col, "_pred")]))
        for col in energy_cols
    ],
    Test = [mean(abs.(
        data[("test", )][:, col] .-
        data[("test", )][:, string(col, "_pred")]))
        for col in energy_cols
    ]
)
```
Mean Absolute Error
:::

:::{#tbl-RMSE-error}
```{julia}
#| label: test-error-squared

RMSE_df = DataFrame(
    features = energy_cols,
    Train = [sqrt(mean((data[("train", )][:, col] .- data[("train", )][:, string(col, "_pred")]).^2))
        for col in energy_cols
    ],
    Calib = [sqrt(mean((data[("calib", )][:, col] .- data[("calib", )][:, string(col, "_pred")]).^2))
        for col in energy_cols
    ],
    Test = [sqrt(mean((data[("test", )][:, col] .- data[("test", )][:, string(col, "_pred")]).^2))
        for col in energy_cols
    ]
)
```
Root Mean Square Error
:::

Looking at the residual histograms in @fig-calib-residuals-histograms, we see they resemble Normal distributions centered on zero. This indicates we will be able to conformalize the model to obtain a probabilistic forecast. Solar residuals have most values at zero because the model correctly predicts no solar energy production at night. We get around this by using the combined energy as we don't explicitly have to know the solar and the wind energy production.

:::{#fig-calib-residuals-histograms}
```{julia}
#| label: plot-residuals

@df data[("test", )] plot(
    layout=@layout((5, 1)),
    size=(800, 600),
    legend=false,
    histogram(
        ylabel="Solar",
        data[("test", )].Solar .- data[("test", )].Solar_pred,
        color=cmap["Solar"]
    )
    ,
    histogram(
        ylabel="Wind",
        data[("test", )].Wind .- data[("test", )].Wind_pred,
        color=cmap["Wind"]
    ),
    histogram(
        ylabel="Total Energy",
        data[("test", )].TotalEnergy .- data[("test", )].TotalEnergy_pred,
        color=cmap["TotalEnergy"]
    ),
    histogram(
        ylabel="DAP",
        data[("test", )].DAP .- data[("test", )].DAP_pred,
        color=cmap["DAP"]
    ),
    histogram(
        ylabel="SSP",
        data[("test", )].SSP .- data[("test", )].SSP_pred,
        color=cmap["SSP"]
    )
)
```
Calibration Data Residuals
:::

# Conformalizing LSTM

We are satisfied with the performance of the LSTM, but there is an unquantified risk in using it because it only outputs a point forecast. Our first method to deal with this is to conformalize the model with calibration data. This will allow us to get confidence intervals around the prediction which can be used in many ways by the operator. This is a powerful and simple method to extend the utility of a model like the LSTM.

## Implementation

The process is essentially accomplished in two steps. First, non-conformity scores are calculated for each prediction in the calibration data. Second, a desired quantile is retrieved which represents the probability that the true value will be within a certain amount of non-conformity with that quantile. For our purposes, nonconformity scores are just the mean error and they are indexed by time. 


## Performance

The heatmaps in @fig-nonconformity-heatmaps show the non-conformity of the Total Energy, DAP, and SSP show the results. The x-axis is the time of day, and the y-axis is the probability of the true value being within the non-conformity score indicated by the color bar. Blue values are desirable as they indicate a low non-conformity score while red indicates a high non-conformity score. For instance, at 3:00 AM, the Total Energy score was low with a value of around 200 with probability 1. So we can be very confident the true value will be within 200 MWh of the prediction. Conversely, the DAP at 7:00 AM has a relatively high non-conformity score that dips down below the 0.5 quantile. This means that we cannot even be sure that true DAP will be within 40 GBP/MWh with better than 50% probability.

```{julia}
#| label: conformalizing-LSTM
#| output: false

# creattng a copy of the calibration data
CP_data = deepcopy(data[("calib",)])[:, :]

# converting all excpet datetime to Float32

CP_data.Time = Time.(CP_data.DateTime)

for col in energy_cols
    CP_data[!, col] = Float32.(CP_data[!, col])
end

for col in energy_cols
    CP_data[!, Symbol(string(col, "_score"))] = abs.(CP_data[!, col] .-  CP_data[!, Symbol(string(col, "_pred"))])
end


# getting rid of everything except the scores
select!(CP_data, [:Time; [Symbol(string(col, "_score")) for col in energy_cols]])

# making convenience function to calculate the nonconformity scores
# setting default CI to be .6 because the predictions are not very good
# still, this will be very useful for the conditional value at risk optimization

CP_data = groupby(CP_data, :Time)

CP(col, time, α=0.75) = quantile(CP_data[(time, )][:, Symbol(string(col, "_score"))], α)
```

:::{#fig-nonconformity-heatmaps}
```{julia}
#| label: plot-nonconformity

alphas = 0.0:0.01:1.0
one_day = Time(0):Minute(30):Time(23,30)

plot(
    size=(500, 500),
    layout = @layout((3, 1)),
    xticks = daily_xticks,
    heatmap(
        xlabel="Time",
        ylabel="P{|y-ŷ| < NC}",
        cbartitle="Energy",
        one_day,
        alphas,
        (t, α) -> CP(:TotalEnergy, t, α),
        color=cgrad(:roma, rev=true)
    ),
    heatmap(
        xlabel="Time",
        ylabel="P{|y-ŷ| < NC}",
        cbartitle="DAP",
        one_day,
        alphas,
        (t, α) -> CP(:DAP, t, α),
        color=cgrad(:roma, rev=true)
    ),
    heatmap(
        xlabel="Time",
        ylabel="P{|y-ŷ| < NC}",
        cbartitle="SSP",
        one_day,
        alphas,
        (t, α) -> CP(:SSP, t, α),
        color=cgrad(:roma, rev=true)
    )
)
```
Nonconformity Scores Probabilities
:::

# Market Trading

The predictions of the energy production and market prices are used to inform the bidding for the following day using different strategies for comparison. The operator cannot store energy or commit to negative energy production. The strategies explored are:

1.  Commit the Point Forecast
2.  Commit the Point Forecast - a 10% confidence interval obtained from Conformal Prediction
3.  Conditional Value at Risk

These strategies are compared to a benchmark of the revenue generated from perfectly predicting and committing the total energy produced. We consider this to be the most reasonable benchmark as anything better amounts to timing the SSP market. Revenue is calculated for this competition according to this formula(@eq-revenue) which approximates the impact of the difference between the energy prediction and actual production on the settlement price.

$$
Revenue = Trade*DAP + \Delta_E (SSP - 0.07 \Delta_E)
$$ {#eq-revenue}
$$
\Delta_E = Actual - Trade
$$
The difference between actual and traded energy is penalized by the SSP and its square multiplied by $0.07$. This is the piece that penalizes for both over and underproduction when SSP is positive which is the norm. While there are times when SSP is negative, they tend to be at times of overproduction so there is not a realistic way to exploit an arbitrage scenario by over-promising and under-delivering during such periods.

```{julia}
#| label: revenue-formula
#| output: false

revenue(traded, actual, dap, ssp) = traded*dap + (actual-traded)*(ssp - 0.07*(actual-traded))
```

## Revenue from Point Prediction

The predicted total energy is used as the traded amount in the day ahead market. Revenue is calculated as shown above using the actual total energy and the actual market prices. This does not consider the forecasts for the market prices and is the most straightforward to implement. Since there is no quantification of risk, there is no indication of the expected value of this energy commitment or possible undesirable outcomes.

```{julia}
#| label: point-prediction-revenue
#| output: false
#| eval: false

for df in data
    df.perfect_energy_revenue = revenue.(df.TotalEnergy, df.TotalEnergy, df.DAP, df.SSP)
    df.point_revenue = revenue.(df.TotalEnergy_pred, df.TotalEnergy, df.DAP, df.SSP)
end

# data.point_revenue = revenue.(data.TotalEnergy_pred, data.TotalEnergy, data.DAP, data.SSP)
```

## Revenue from Conformal Prediction

We concluded that as a general rule, it is possible to reduce risk by under-committing energy rather than over-committing in the day-ahead market. The revenue formula penalizes failing to meet the commitment more. It is a delicate balance and we found that reducing the point prediction by the non-conformity score at the 10% quantile can have a favorable impact on the revenue. This approach could be justified by a game-theory approach which would consider playing the game indefinitely. Currently, this value is arbitrary without a strong justification but is included as an example of how the conformal prediction can and cannot be used.
```{julia}
#| label: conformal-prediction-revenue
#| output: false
#| eval: false

# Conformal Prediction Error interval to use
CPI = 0.10

for df in data
    df.point_plus_10cp = revenue.(
        df.TotalEnergy_pred + CP.(:TotalEnergy, Time.(df.DateTime), CPI),
        df.TotalEnergy, df.DAP, df.SSP)
    df.point_minus_10cp = max.(0, revenue.(
        df.TotalEnergy_pred + CP.(:TotalEnergy, Time.(df.DateTime), CPI),
        df.TotalEnergy, df.DAP, df.SSP))
end
```

## Revenue from Conditional Value at Risk

### Overview

Stochastic optimization of the trade decisions using Conditional Value at Risk allows us to consider aspects that the point prediction and CP method cannot. Specifically, the trade decision can be optimized directly for revenue outcomes while considering uncertainties. This also requires the uncertainties of the market prices to be treated as well. This additional context results in a defensible strategy that can optimize an operator's trading strategy within a specified risk tolerance.

For this strategy, we assume we are risk averse and our goal is to maximize the expected value of some lower quartile of possible outcomes. In this study, we opted for 33% to indicate that more likely than not, in the worst 33% of cases, we will have a certain amount of revenue. This is a more sophisticated method than the previous two and is a more realistic representation of the trading environment. Future work could include a specific risk profile that would specify that, for example, the probability of losing X in any one time period or day must be less than Y% or the probability of ever falling below a certain threshold must be less than Z%.

### Implementation

We implemented CVaR by sampling residuals from the calibration data and adding them to the point forecast. At each prediction step we did the following:

1. Sample 250 residuals from the calibration data. These are indexed by time which captures two key elements simultaneously. First, is that the model may just be more accurate for a given feature at some time. This could be based on weather patterns, demand, or any number of factors. Secondly, it captures that at the 9:00 AM prediction, we are only 49 steps into the future while at the 7:30 AM prediction, we are at 97 steps. We know that error accumulates over time so this is an important factor to consider.
2. Add the residuals to the point forecast to get 250 scenarios of the total energy, DAP, and SSP.
3. Evaluate the revenue gained for each scenario at all available trade amounts. The true energy production is taken as the point forecast plus the scenario energy production residual.
4. At each available trade amount, calculate the mean of the lower 33% of the revenues in the scenarios. This is the CVaR.
5. Find the trade amount with the maximum CVaR.

The results of this process are depicted in @fig-cvar-plot. The multi-colored curves represent different scenarios evaluated for each available trade amount. The color represents how far off the predicted energy production was from the actual energy production. The solid black curve is the mean, or expected value of trading that amount of energy for those scenarios. The dashed black curve is the CVaR. For this optimization problem with a single decision variable, how much to trade, we can graphically see the maximum is at about 700 MWh. So the decision is made to trade that amount and the actual revenue is shown as the green diamond. Also plotted are the "+" showing the revenue from a perfect prediction and commitment of the energy production and the "o" showing the point prediction and associated revenue. The fact that the CVaR revenue is higher than the CVaR curve shows that the actual revenue cannot be known, and that CVaR curve is just the expected value of that quantile. In this case, the maximal CVaR happens to be close to the maximal mean, but it is not always the case. Typically, we would see the CVaR peak at a point off of the peak of the mean curve. The goal is to maximize the expectation of the worst outcomes, but this comes at the cost of not maximizing the outcome. If one had infinite funds and could assume infinite risk, the optimal strategy would be to maximize the expected value. In the real world, we prefer to limit our risk exposure. Lastly, we note that CVaR performs better than the point forecast. With CVaR we have accounted for our uncertainty about the energy production and market prices while the point forecast is only considering production and no uncertainty. This highlights the importance of considering the uncertainty in the predictions and trading.

:::{#fig-cvar-plot}
```{julia}
#| label: cvar-plot-example

#this_trade = rand(1:size(data[("test", )], 1))
#this_time = Time(data[("test", )][this_trade, :DateTime])

this_time = DateTime(2024, 04, 14, 22, 30)
this_trade = findfirst(
    t -> t == this_time, data[("test", )].DateTime
    )
this_time = Time(this_time)

residual_pool = findall(
    row -> Time(row) - Minute(30) <= this_time <= Time(row) + Minute(30),
    data[("calib",)].DateTime
)

residual_pool = data[("calib",)][residual_pool, :]

n = 250
residual_scenarios = residual_pool[rand(1:size(residual_pool, 1), n), :]

residual_scenarios.TotalEnergy_resid = residual_scenarios.TotalEnergy .- residual_scenarios.TotalEnergy_pred
residual_scenarios.DAP_resid = residual_scenarios.DAP .- residual_scenarios.DAP_pred
residual_scenarios.SSP_resid = residual_scenarios.SSP .- residual_scenarios.SSP_pred
select!(residual_scenarios, :TotalEnergy_resid, :DAP_resid, :SSP_resid)

# establish the range of energy to trade
TradeEnergyRange = DataFrame(
    Trade = range(extrema(data[("test", )].TotalEnergy_pred)..., length=200),
)

this_predict = data[("test", )][this_trade, [:TotalEnergy_pred, :DAP_pred, :SSP_pred, :TotalEnergy, :DAP, :SSP]]

TotalEnergyRange = crossjoin(TradeEnergyRange, residual_scenarios)

TotalEnergyRange.Revenue .= NaN
for row in eachrow(TotalEnergyRange)
    row.Revenue = revenue(
        row.Trade,
        this_predict.TotalEnergy_pred + row.TotalEnergy_resid,
        this_predict.DAP_pred + row.DAP_resid,
        this_predict.SSP_pred + row.SSP_resid
    )
end

summary_df = combine(groupby(TotalEnergyRange, :Trade)) do group
    revenue = group.Revenue
    mean_revenue = mean(revenue)
    median_revenue = median(revenue)
    quantile_33 = quantile(revenue, 0.33)
    lowest_33_mean = mean(sort(revenue)[1:round(Int, length(revenue)*0.33)])

    DataFrame(
        Trade = first(group.Trade),
        Mean = mean_revenue,
        Median = median_revenue,
        Quantile33 = quantile_33,
        Lowest33Mean = lowest_33_mean
    )
end

# scatter plot of the revenue for each scenario
@df TotalEnergyRange scatter(
    xlabel="Trade Amount",
    ylabel="Revenue",
    :Trade, :Revenue,
    markerstrokewidth=0, ms=2, α=0.05,
    label="Scenario Revenue",
    mz=:TotalEnergy_resid,
    cbartitle="Total Energy Residual",
    color=cgrad(:turbo, rev=true)
)

# plot the revenue for the different strategies
@df summary_df plot!(
    :Trade,
    [:Mean  :Lowest33Mean],
    color=:black, lw=5,
    linestyle=[:solid :dash],
)

@df data[("test", )][[this_trade], :] scatter!(
    :TotalEnergy, :perfect_energy_revenue,
    label="Perect Energy Prediction",
    shape=:+, ms=10, markerstrokewidth=5, mc=:black
)

@df data[("test", )][[this_trade], :] scatter!(
    :TotalEnergy_pred, :point_revenue,
    label="Point Energy Prediction",
    shape=:o, ms=10, mc=:black
)

maximal_cvar = summary_df[findmax(summary_df.Lowest33Mean)[2], :Trade]
cvar_revenue = revenue(
    maximal_cvar,
    this_predict.TotalEnergy,
    this_predict.DAP,
    this_predict.SSP
)

scatter!(
    [maximal_cvar], [cvar_revenue],
    label="CVAR",
    shape=:diamond, ms=10, mc=:green
)
```
Conditional Value at Risk Example (2024-04-14 22:30)
:::

```{julia}
#| label: cvar-function
#| output: false
#| eval: false


#=
# set the conditional value at risk level
# we want to maximize the expectation of the lowest 5% of the revenue
α=0.33
# extent of the trade amount to be considered
trade_range = [extrema(data[(:train,)].TotalEnergy_pred)...]
trade_range = DataFrame(Trade = range(first(trade_range), last(trade_range), length=200))

n = 250

for df in data
    df.cvar_trade .= NaN
    Threads.@threads for row in eachrow(df)
        this_time = Time(row.DateTime)
        
        residual_pool = findall(
            t -> t in [this_time - Minute(30), this_time, this_time + Minute(30)], Time.(data[(:calib,)].DateTime)
            )

        residual_pool = data[(:calib,)][residual_pool, :]
        residual_scenarios = residual_pool[rand(1:size(residual_pool, 1), n), :]

        residual_scenarios.TotalEnergy_resid = residual_scenarios.TotalEnergy .- residual_scenarios.TotalEnergy_pred
        residual_scenarios.DAP_resid = residual_scenarios.DAP .- residual_scenarios.DAP_pred
        residual_scenarios.SSP_resid = residual_scenarios.SSP .- residual_scenarios.SSP_pred

        TotalEnergyRange = crossjoin(trade_range, residual_scenarios)

        TotalEnergyRange.Revenue .= NaN
        for row in eachrow(TotalEnergyRange)
            row.Revenue = revenue(
                row.Trade,
                row.TotalEnergy_pred .+ row.TotalEnergy_resid,
                row.DAP_pred .+ row.DAP_resid,
                row.SSP_pred .+ row.SSP_resid
            )
        end

        summary_df = combine(groupby(TotalEnergyRange, :Trade)) do group
            revenue = group.Revenue
            mean_revenue = mean(revenue)
            median_revenue = median(revenue)
            quantile_33 = quantile(revenue, 0.33)
            lowest_33_mean = mean(sort(revenue)[1:round(Int, length(revenue)*0.33)])

            DataFrame(
                Trade = first(group.Trade),
                Mean = mean_revenue,
                Median = median_revenue,
                Quantile33 = quantile_33,
                Lowest33Mean = lowest_33_mean
            )
        end

        maximal_cvar = summary_df[findmax(summary_df.Lowest33Mean)[2], :Trade]
        cvar_revenue = revenue(
            maximal_cvar,
            row.TotalEnergy,
            row.DAP,
            row.SSP
        )

        row.cvar_trade = maximal_cvar
    end

    df.cvar_revenue = revenue.(df.cvar_trade, df.TotalEnergy, df.DAP, df.SSP)
end

CSV.write("src/data/data_predictions_revenues.csv", vcat(data...))
=#
```

## Performance

The plot of cumulative revenue over the testing period for each trading strategy is shown in @fig-cumulative-revenue. The perfect forecast is a point of reference for what would be achieved if the operator could perfectly predict the production and not trade on the real-time market at all. As expected, this is the highest value even though it does not consider market prices. Next, we see that CP-adjusted commitment outperforms the other strategies. As alluded to earlier, this may be a case of gambling and getting lucky as there is no justification for this reduction other than that it happened to perform well. Conversely, there may be a strong underlying reason which would explain why this is a good strategy. Next, we see that CVaR is just behind the CP-adjusted strategy. Lastly, the point forecast performed the worst as it suffered the biggest loss in the first week and never fully recovered to the level of the other two strategies.


:::{#fig-cumulative-revenue}
```{julia}
#| label: revenue-plots

@df data[("test", )] plot(
    :DateTime,
    [cumsum(:perfect_energy_revenue) cumsum(:point_revenue) cumsum(:point_minus_10cp) cumsum(:cvar_revenue)],
    label=["Perfect" "Point" "Conformal" "CVaR"],
    color=[:black :blue :red :green],
    lw=3,
)
```
Test Data Cumulative Revenues
:::


# Conclusions

The revenue from all three strategies built from the LSTM are on the same order of magnitude and off by a factor of two from the perfect energy production revenue. This indicates that our model and strategies are promising in their ability to capture the highly nonlinear and complex dynamics of the system, time dependency, and uncertainties. It also indicates there is room for improvement. We have identified the areas below as good places to start for future work:

1. Incorporate more data. We have purposely used a small subset of the available data sources, features, and history to build and test this model as a simplistic starting point and proof of concept. Specifically, demand forecasts and weather from more nearby locations would be useful.
2. Feed longer sub-sequences to the LSTM. Currently, the LSTM is updating its state only on the last step and then predicting the next step. It would be better to provide a lookback window of at least 24 hours so the seasonality would be learned implicitly rather than provided explicitly.
3. Predict optimal (or near-optimal) trade amounts directly. Once forecasts have been created for the features, train a model that takes those probabilistic forecasts to predict the optimal trade amount. This may offer a more direct path to maximizing revenue, although it would not be explainable as CVaR or other strategies are.
4. Test the CVaR on different risk profiles.

The problems addressed in this study are practical, real-world decisions that renewable energy production operators must answer every day. This report shows how advanced technologies and methodologies that rely on probabilistic approaches are within reach and can be used to limit risk for these operators. In the long run, reducing this risk will make investment in renewable energy more palatable and bring more systems online which will be a net benefit for the environment and the economy.